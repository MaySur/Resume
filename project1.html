<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Source Scan</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" href="./style/index.css">

</head>
<body>
    <div id="main">
        <section  class="page">
    
            <a href="index.html" > &#8592; Go Back</a>
            <h1 class="ss-header">Source Scan</h1>
            <div id="page">

                <div id="socials">
                    <a href="https://github.com/MaySuresh/Source-Scans" target="_blank">Project Repository</a>
                </div>
            </div>
           

        </section> 
        <section class="page" style=" border-bottom: 1px solid grey;" >
            <h3 class="summ-header">Personal Note:</h3>
            <p  class="ss-summary">  
                As this was a collaborative endeavor, I undertook the responsibility of front-end development, despite my novice status in the field at the time. In view of my limited expertise, I made the decision to leverage the Flask web framework. Despite encountering various challenges such as constraints pertaining to timing, resource availability, and experience, our team was able to effectively create a functional python worker integrated with a Reddit API. Although the project could not be fully completed and deployed, we made substantial progress. Furthermore, I intend to continue working on this project independently with the goal of transforming it from a cloud application to a fully functional web application.
            </p>           
            </section>

            <section class="page" style=" border-bottom: 1px solid grey;" >
                <h3 class="summ-header">About Project:</h3>
                <p  class="ss-summary">  
                    In the year 2022, it is evident that news stories are no longer limited to mainstream news sources. With the vast amount of information available on the internet, breaking news often surfaces on online message boards such as Reddit, directly from the source, before reaching mainstream network news channels. However, gathering information from the internet can prove to be a daunting task for individuals, given the sheer amount of news available from numerous places on the internet. Therefore, a software solution is proposed to streamline this process, consisting of the following three components:
                    </p> 
                    <ul>
                        <li style="list-style:decimal ; padding-bottom: 30px;">
                            API Reddit Scraper: Designed in Python language, this component takes a list of predetermined 'news source' subreddits, such as r/news, r/global news, and r/politics, and uses keywords provided by the user to gather all pertinent information surrounding the provided topic. The scraper's aim is to filter out irrelevant posts and provide only relevant submissions from each news-based subreddit.

                        </li>
                        <li style="list-style:decimal;  padding-bottom: 30px;;">
                            Redis Database: The Redis database is designed around the concept of key terms inputted by the client and holds the gathered information after it is filtered. This database is called after the use of the scraper, and is needed for the WebUIâ€™s query, in order to return the results to the user.
                        </li>
                        <li style="list-style:decimal;  padding-bottom: 30px;;">
                            HTML User Interface (WebUI): The WebUI component provides users with an easy-to-use interface, enabling them to filter information and display only relevant submissions. The WebUI queries the database after the scraper is deployed, returning submissions to the user that they can then view the details of.
                        </li>
                                              
                    </ul>
                    <p  class="ss-summary">
                        The three-piece program aims to provide users with relevant news stories while saving them time and streamlining the news-searching process. By creating a program that can identify and filter for useful information based on submitted key terms, immediately returning that resulting information into a database, and displaying that information in the database to the user, Redditors can ensure that they receive relevant news updates and avoid potentially misleading or fake news sources.

                    </p>
                          
                </section>
                <div id="page">

                    <div id="socials">
                       <p style="margin-bottom: 0;"> For more information about the project download our document: <a href="./assets/CSC 468 Project .pdf" target="_blank">Project Document</a></p> 
                       <p style="margin-bottom: 100px;" > For our project poster: <a href="./assets/SourceScan Poster.pptx" target="_blank">Project Document</a></p>                     </div>
                </div>
    </div>

</body>
</html>